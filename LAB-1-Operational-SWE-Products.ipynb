{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operational Snow Water Equivalent (SWE) Products \n",
    "In this lab we will look at operational SWE products. These are standard products, produced in near real time (NRT), that are publically avalible. A word of cacution: as you might remember from the lectures, estimating SWE in the mountains is hard. Operational SWE products perform better in large, flat areas with consisten depth and densisty of snowpack across many square kilometeres. Fortunatly there is a lot of development in this space and some of the products are consistently improving. So these methods may be useful for future, better datasets as well. \n",
    "\n",
    "## Two types of SWE products: Measurements and Models\n",
    "There are two main catagories of operational SWE products. Measurements of SWE and process based model estiamtes of SWE. We will explore an example of both. For Measurement of SWE, we will look at the estimate from the unified AMSR SWE products which provide daily estames of global SWE (albet with some caviats). For process based model estaimtes of SWE we will explore the NRT ERA-5 SWE estimates from ECMWF. \n",
    "\n",
    "Goals of the lab:\n",
    "- Gain familiarity with SWE plots.\n",
    "- Understand the two main sources of SWE estimates: measurements and models\n",
    "- Gain familiarty with data interpolation\n",
    "- Data sceince techniques to visualize the SWE in the context of historical records"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1: AMSR-Unified SWE estimates\n",
    "\n",
    "The first product we are going to look at is the AMSR unifed SWE product. These data are collected from satellies that measure the emission of microwave radiation from earth. Snow scatters and reduces this signal, so based on the measured reduction in passive microwave signal, we can estimate the snow water equivalent. This method works best in areas that have shallow snowpack and are flat for hundreds of kilometers. \n",
    "\n",
    "This AMSR Unified SWE product is produced using data collected by the Advanced Microwave Scanning Radiometer (AMSR-E) on board the Aqua satellite from June 2002 to October 2011, and from the Advanced Microwave Scanning Radiometer 2 (AMSR2) on board the JAXA GCOM-W1 satellite from July 2012 to the present. The purpose of the AMSR Unified Data Set is to provide the science community with intercalibrated climate products from both the AMSR-E and the AMSR2 instruments. \n",
    "\n",
    "The data sets are archived here:\n",
    "\n",
    "AMSR-E SWE: 2002-2011\n",
    "https://nsidc.org/data/AE_DySno/versions/2\n",
    "\n",
    "\n",
    "AMSR2 SWE: 2012-now \n",
    "https://nsidc.org/data/AU_DySno/versions/1\n",
    "\n",
    "\n",
    "These data are avalible as daily, 5-day maximum, and monthly maximum datasets. We will look at the daily data in this lab excersize. \n",
    "## Set up the Lab workspace\n",
    "To explore these datasets we need to import the require packages for geospatial analysis in python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import geopandas as gpd \n",
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import os\n",
    "import contextily as ctx\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose an Area of Interest\n",
    "We have three different AOIs. Choose one of the following to complete your lab: Langtang catchment in Nepal, Panjsher basin in Afganistan, or wangchu watershed in Bhutan. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets look at the Area of Interest (AOI) on a map. Pick one of the following:\n",
    "\n",
    "#choose on of the following areas for your labratory. \n",
    "#Feel free to explore each of them!\n",
    "#panjsher_basin_afghanistan\n",
    "#wangchu_watershed_bhutan\n",
    "#langtang_catchment_nepal\n",
    "############## INSERT AOI WATERSHED NAME HERE ###################\n",
    "watershedName='panjsher_basin_afghanistan'\n",
    "#################################################################\n",
    "aoiFile=watershedName+'_wgs84.shp'\n",
    "basinMaskFile=watershedName+'_basinMask.tif'\n",
    "aoi_AMSR_SWE=watershedName+'_AMSR_SWE.tif'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the Area of Interest on a basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load the shapefile with geopandas and display on a basemap with contextily\n",
    "#The 'EPSG' codes are standerdized information that discribe which projection the datasets \n",
    "#are in. We want to add basemap in same projection as the SWE data and AOI data\n",
    "\n",
    "#load\n",
    "AOI = gpd.read_file(aoiFile)\n",
    "AOI.crs= \"EPSG:4326\" #({'init': 'epsg:4326'})\n",
    "\n",
    "#plot\n",
    "ax = AOI.plot(edgecolor=\"purple\", facecolor=\"None\")\n",
    "ctx.add_basemap(ax, crs=\"EPSG:4326\"); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the AMSR-E SWE data\n",
    "\n",
    "Fist, it is importnat to see how the data are delivered. The datasets are delivered for the entire northern hemisphere as a single image each day in the daily dataset. This is not very useful for looking a a small basin! Lets see what the full dataset look like for one day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#february 18, 2010 Northerm hemisphere AMSR product.\n",
    "#- FIX: the AMSR-2 data is .he5 not .hdf \n",
    "#print one day of the full AMSR-e data. need to make still."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interesting? This is a unique projection. More information is here:\n",
    "https://nsidc.org/ease/ease-grid-projection-gt\n",
    "\n",
    "add some more information about the data storage format for student info\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore AMSR SWE for our Area of Interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have reprojected, cropped, and assmebeled data cubes of the full AMSR Unifed SWE records for this lab for each area of interest. \n",
    "\n",
    "A data cube is a stack of data, for earth science datasets, one common type of datacube is a \"time/space\" cube. This is when we have data for a specific area, for many days, all assembled into a single file for analysis. For this lab we will be working with time/space datacubs of AMSR-U SWE data. \n",
    "\n",
    "to start lets load up the datacube, and visualize it in a few days to get a since of the SWE data that we have to work with. \n",
    "## Load SWE datacube and check size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#load the basin mask\n",
    "bMask=rio.open(basinMaskFile)\n",
    "basinMask = bMask.read()\n",
    "basinMask=np.squeeze(basinMask)\n",
    "\n",
    "#load the SWE dataset\n",
    "aoi_AMSR_SWE=watershedName+'_AMSR_SWE.tif'\n",
    "SWE=rio.open(aoi_AMSR_SWE)\n",
    "SWEarray = SWE.read()\n",
    "numel=SWEarray.shape\n",
    "\n",
    "\n",
    "print(numel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have loaded the SWE datacube for our study area. the ***'.shape'*** command lets us see the size of our datacube. From this, can you figure out how many days of data are in the datacube? what about how many measurements per day?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot SWE at one location for entire data record\n",
    "Lets load up the dates for these data, which are stored seperatly and plot one of the pixels in the datacube for the whole record of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dateFile=watershedName+'AMSR_sweDates.csv'\n",
    "SWEdf=pd.read_csv(dateFile,header=None,names=['sweDates'])\n",
    "SWEdf['SWE_mm']=pd.DataFrame(SWEarray[:,4,5])#,columns=['SWE_mm'],index=)\n",
    "SWEdf['sweDates']=pd.to_datetime(SWEdf['sweDates'],format='%Y%m%d')\n",
    "SWEdf=SWEdf.set_index('sweDates')\n",
    "\n",
    "#values above 240 are various flags for no data, we will set to NaN\n",
    "SWEdf[SWEdf>240]=np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the data organized into a DataFrame, lets plot one of the pixels in the datacube for the whole record of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create figure and plot space\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Add x-axis and y-axis\n",
    "ax.plot(SWEdf.index.values,\n",
    "        SWEdf['SWE_mm'],\n",
    "        color='purple')\n",
    "\n",
    "# Set title and labels for axes\n",
    "ax.set(xlabel=\"Date\",\n",
    "       ylabel=\"Snow Water Equivalent (mm)\",\n",
    "       title=\"Daily Snow Water Equivalent \\n\" + watershedName)\n",
    "\n",
    "# Rotate tick marks on x-axis\n",
    "plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore one water year of data\n",
    "Lets look closey at one water year of data, the 2004-2005 water year. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "WY_04_05=SWEdf['2004-10-01':'2005-09-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create figure and plot space\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Add x-axis and y-axis\n",
    "ax.plot(WY_04_05.index.values,\n",
    "        WY_04_05,\n",
    "        color='purple')\n",
    "\n",
    "# Set title and labels for axes\n",
    "ax.set(xlabel=\"Date\",\n",
    "       ylabel=\"Snow Water Equivalent (mm)\",\n",
    "       title=\"Daily Snow Water Equivalent \\n\" + watershedName)\n",
    "\n",
    "# Rotate tick marks on x-axis\n",
    "plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "anything look weird? Why does the SWE disapear on lots of days within the dataseieres?\n",
    "\n",
    "\n",
    "This is becasue the satellite does not take a measurement everyday. Sometimes the pixel is not images by the satellite, so there are fill values in the datasets on those days. What can we do about this? one solution is to interpolate the value based on measurements on the preceeding days and following days that are valid measurements. With remote sensing data of snow, this is very common. Many times there are numerious days where we just do not have a good measurement. This can be becuase of cloud cover, no picture was taken on that day, or the picture is of poor quality for a variaety of reaseons. (off nadir, noise, ect....)\n",
    "\n",
    "## Fill and smooth AMSR SWE datacube\n",
    "Now we will smooth the data. This is an example of a simle way to smooth the data. In the lectures, Karl will show you some of our more advanced routines and we will see the quality of the research grade SWE products that include more difficult time/space smoothing. For now, we will explore how smoothing works with some simpler methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WY_04_05.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remake the graph with a cubic spline interpolation of the point estimates from AMSR and then use a rolling average\n",
    "\n",
    "#calculate the cubic spline estimate of the AMSR data \n",
    "amsrSWE_interp=WY_04_05['SWE_mm'].interpolate(method='cubicspline')\n",
    "\n",
    "# 7 day  moving average of the interpolated data\n",
    "amsrSWE_avg=amsrSWE_interp.rolling(7).mean()\n",
    "\n",
    "\n",
    "#plot the smoothed output.\n",
    "# Create figure and plot space\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Add x-axis and y-axis\n",
    "ax.plot(amsrSWE_avg.index.values,\n",
    "        amsrSWE_avg,\n",
    "        color='purple')\n",
    "\n",
    "# Set title and labels for axes\n",
    "ax.set(xlabel=\"Date\",\n",
    "       ylabel=\"Snow Water Equivalent (mm)\",\n",
    "       title=\"Daily Snow Water Equivalent \\n\" + watershedName)\n",
    "\n",
    "# Rotate tick marks on x-axis\n",
    "plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ADD have students pick a water year \n",
    "#and copy/paste/edit the code they need to smooth another water year of SWE data in to the cells below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate volume of SWE in the basin each day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def compute_volume(dataCube,basinMask):\n",
    "    idx=np.nonzero(basinMask)\n",
    "    numValid=np.count_nonzero(basinMask)\n",
    "    numel=dataCube.shape\n",
    "    output=np.zeros(numel[0])   \n",
    "    for i in range(numel[0]):\n",
    "        daySWE=np.squeeze(dataCube[i,:,:])\n",
    "        \n",
    "        #remeber that values above 240 are fill in the original dataset, so we dont want to add - assume missing data\n",
    "        daySWE[daySWE>240]=0\n",
    "        \n",
    "        #volume of water in each pixel\n",
    "        #SWE*area=volumne of water - we want volume in cubic kilometers\n",
    "        swe2km3=(31**2)/1000000\n",
    "        daySWE=daySWE*swe2km3\n",
    "        #volume of water in the basin\n",
    "        #all data for this lab has been reporjected to 31km pixels equivalent to the ERA-5 grid.\n",
    "        #AMSR-U SWE is in 25km native resolution      \n",
    "        output[i]=daySWE[idx].sum()\n",
    "    return output\n",
    "\n",
    "dailyBasinSnowWaterVolume=compute_volume(SWEarray,basinMask)\n",
    "dailyBasinSnowWaterVolume.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets make a new dataframe with the new volme data included "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dateFile=watershedName+'AMSR_sweDates.csv'\n",
    "SWEdf=pd.read_csv(dateFile,header=None,names=['sweDates'])\n",
    "SWEdf['km3 snowpack storage']=pd.DataFrame(dailyBasinSnowWaterVolume)\n",
    "SWEdf['sweDates']=pd.to_datetime(SWEdf['sweDates'],format='%Y%m%d')\n",
    "SWEdf=SWEdf.set_index('sweDates')\n",
    "SWEdf.head()\n",
    "\n",
    "# Create figure and plot space\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Add x-axis and y-axis\n",
    "ax.plot(SWEdf.index.values,\n",
    "        SWEdf['km3 snowpack storage'],\n",
    "        color='purple')\n",
    "\n",
    "# Set title and labels for axes\n",
    "ax.set(xlabel=\"Date\",\n",
    "       ylabel=\"water volume in snow (km3)\",\n",
    "       title=\"Daily water stored in the snowpack in the basin \\n\" + watershedName)\n",
    "\n",
    "# Rotate tick marks on x-axis\n",
    "plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets look at basin wide water volume for the 2004-2005 water year again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "WY_04_05=SWEdf['2004-10-01':'2005-09-30']\n",
    "# Create figure and plot space\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Add x-axis and y-axis\n",
    "ax.plot(WY_04_05.index.values,\n",
    "        WY_04_05,\n",
    "        color='purple')\n",
    "\n",
    "# Set title and labels for axes\n",
    "ax.set(xlabel=\"Date\",\n",
    "       ylabel=\"Snow Water Equivalent (km3)\",\n",
    "       title=\"Daily Snow Water Equivalent \\n\" + watershedName)\n",
    "\n",
    "# Rotate tick marks on x-axis\n",
    "plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can really see those fill values coming into our data. lets smooth these also and see what it looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#calculate the cubic spline estimate of the AMSR data \n",
    "amsrSWE_interp=WY_04_05['km3 snowpack storage'].interpolate(method='cubicspline')\n",
    "\n",
    "# 7 day  moving average of the interpolated data\n",
    "amsrSWE_avg=amsrSWE_interp.rolling(7).mean()\n",
    "\n",
    "\n",
    "#plot the smoothed output.\n",
    "# Create figure and plot space\n",
    "fig, ax = plt.subplots(figsize=(10, 10))\n",
    "\n",
    "# Add x-axis and y-axis\n",
    "ax.plot(amsrSWE_avg.index.values,\n",
    "        amsrSWE_avg,\n",
    "        color='purple')\n",
    "\n",
    "# Set title and labels for axes\n",
    "ax.set(xlabel=\"Date\",\n",
    "       ylabel=\"Snow Water Equivalent (km3)\",\n",
    "       title=\"Daily Snow Water Equivalent \\n\" + watershedName)\n",
    "\n",
    "# Rotate tick marks on x-axis\n",
    "plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important to remeber:\n",
    "swe is not streamflow.\n",
    "lots can happen to the water in the environmetn before it gets to the stream\n",
    "these are estimates. operationapl products are realy poor over mountainous terrain.\n",
    "more importnat than actual values are the tols and techniques that we can use to work with the data and get information from int (i.e SWE to water volume) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# PART 2: ERA-5 SWE\n",
    "lets look at the ERA-5 data now. \n",
    "\n",
    "add url to era-5 data, add intro text\n",
    "\n",
    "explain it will be the same operaiton as we did with the AMSR data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#clean up our workspace we dont need to keep some of the data above loaded anymore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load ERA-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aoi_ERA5_SWE=watershedName+'_ERA5_SWE.tif'\n",
    "SWE=rio.open(aoi_ERA5_SWE)\n",
    "SWEarray = SWE.read()\n",
    "numel=SWEarray.shape\n",
    "print(numel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "data frame of era5 + dates for one pixel (same pixel as the AMSR part of the lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dateFile=watershedName+'ERA5_sweDates.csv'\n",
    "SWEdf=pd.read_csv(dateFile,header=None,names=['sweDates'])\n",
    "SWEdf['SWE_mm']=pd.DataFrame(SWEarray[:,4,5])#,columns=['SWE_mm'],index=)\n",
    "SWEdf['sweDates']=pd.to_datetime(SWEdf['sweDates'],format='%d-%b-%Y %H:%M:%S')\n",
    "SWEdf=SWEdf.set_index('sweDates')\n",
    "SWEdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create figure and plot space\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# Add x-axis and y-axis\n",
    "ax.plot(SWEdf.index.values,\n",
    "        SWEdf['SWE_mm'],\n",
    "        color='purple')\n",
    "\n",
    "# Set title and labels for axes\n",
    "ax.set(xlabel=\"Date\",\n",
    "       ylabel=\"Snow Water Equivalent (mm)\",\n",
    "       title=\"Daily Snow Water Equivalent \\n\" + watershedName)\n",
    "\n",
    "# Rotate tick marks on x-axis\n",
    "plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look Different? ERA5 gives a much longer historical record of the SWE for the location. This is a nice feture of the models and a dangerous one. They can calculate values for times when they do not have much data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "look at 2004-2005\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add code here\n",
    "WY_04_05=SWEdf['2004-10-01':'2005-09-30']\n",
    "\n",
    "# Create figure and plot space\n",
    "fig, ax = plt.subplots(figsize=(15, 10))\n",
    "\n",
    "# Add x-axis and y-axis\n",
    "ax.plot(WY_04_05.index.values,\n",
    "        WY_04_05,\n",
    "        color='purple')\n",
    "\n",
    "# Set title and labels for axes\n",
    "ax.set(xlabel=\"Date\",\n",
    "       ylabel=\"Snow Water Equivalent (mm)\",\n",
    "       title=\"Daily Snow Water Equivalent \\n\" + watershedName)\n",
    "\n",
    "# Rotate tick marks on x-axis\n",
    "plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no need to smooth! one part of the model outputs is that they are continous. the physical equations are used to generate estimates between measurements, this is a form of \"data assimmilarion\" where the combination of models and measuremtns enable you to make the best estimate possible, considering all sourceig of inforation you have avalible, at any timestep.\n",
    "\n",
    "Now that we have so many years of data, lets make a plot that lets us contextualize any years data wihtin the historical context for that region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(SWEdf.index.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "WY_04_05=SWEdf['2004-10-01':'2005-09-30']\n",
    "\n",
    "\n",
    "# Create figure and plot space\n",
    "#fig, ax = plt.subplots(figsize=(10, 10))\n",
    "plt.figure(figsize=(15,10));\n",
    "#plot all the background years\n",
    "yrs=np.unique(SWEdf.index.year)\n",
    "numYears=len(yrs)-1\n",
    "\n",
    "for i in range(numYears):\n",
    "    sDate=str(yrs[i])+'-10-01'\n",
    "    eDate=str(yrs[i+1])+'-09-30'\n",
    "    WY=SWEdf[sDate:eDate]\n",
    "\n",
    "\n",
    "# Add x-axis and y-axis - x axis is not year this tim ebecuase we have lots of years overlaied\n",
    "    plt.plot(list(range(len(WY))),\n",
    "            WY,\n",
    "            color='grey')\n",
    "\n",
    "\n",
    "# Rotate tick marks on x-axis\n",
    "#plt.show()\n",
    "#xData=list(range(len(WY_04_05)))\n",
    "#now lets highlight the 2004-2005 water year\n",
    "\n",
    "# Add x-axis and y-axis\n",
    "plt.plot(list(range(len(WY_04_05))),\n",
    "         WY_04_05,\n",
    "         color='purple')\n",
    "\n",
    "# Set title and labels for axes\n",
    "titleText='Daily Snow Water Equivalent \\n' + watershedName\n",
    "plt.title(titleText);\n",
    "plt.xlabel(\"Water Year Days\");\n",
    "plt.ylabel(\"Snow Water Equivalent (mm)\");\n",
    "#plt.setp(ax.get_xticklabels(), rotation=45)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This graph gives some context of the highlighted year we are interested in, in the context of other years. But the graph is still kind of messy. Lets look at another way we can visualize a year of interest in the context of the historical record. What is the driest year? The wettest year? To figure this out, and plot them along with some more historical context, we will use on of the more powerful datascience functions in python the \"GroupBy\" funciton you can use on pandas dataframes. We can use GroupBy to find the maximum SWE of each calendar year, which we can see from the above graph, for this pixels occurs at peak SWE each spring. [add some more info about group by and some links to good online references]  First, lets use GroupBy to see what the peak SWE was each year for this pixel. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use groupby to split the dataframe into tables for each year, and then find the maximum value in the 'SWE_mm' column\n",
    "peakSWE=SWEdf.groupby(SWEdf.index.year)['SWE_mm'].max().reset_index()\n",
    "#the data goes into february 2021, so we want to drop the 2020-2021 water year as it is not yet to peak SWE\n",
    "peakSWE=peakSWE[:-1]\n",
    "#view results\n",
    "print(peakSWE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a list of the peak SWE each year, we can use this information to identify the water year that had the deepest snowpack and the water year that had the shallowest snowpack for our contextualization graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#what was the driest year?\n",
    "dryYear=peakSWE.loc[peakSWE[\"SWE_mm\"].idxmin()]['sweDates']\n",
    "print('driest year:', dryYear, 'peak SWE', peakSWE[\"SWE_mm\"].min(), 'mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#what was the wettest year? for this we use .idxmax() instead of .idxmin()\n",
    "wetYear=peakSWE.loc[peakSWE[\"SWE_mm\"].idxmax()]['sweDates']\n",
    "print('wettest year:', wetYear, 'peak SWE', peakSWE[\"SWE_mm\"].max(), 'mm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numYears=[dryYear, wetYear]\n",
    "print(numYears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how different are the wettest and the driest year?\n",
    "plt.figure(figsize=(15,10));\n",
    "\n",
    "numYears=[dryYear, wetYear]\n",
    "for i in numYears:\n",
    "    sDate=str(i-1)+'-10-01'\n",
    "    eDate=str(i)+'-09-30'\n",
    "    WY=SWEdf[sDate:eDate]\n",
    "\n",
    "\n",
    "# Add x-axis and y-axis - x axis is not year this tim ebecuase we have lots of years overlaied\n",
    "    plt.plot(list(range(len(WY))),\n",
    "            WY,\n",
    "            color='grey')\n",
    "\n",
    "titleText='Daily Snow Water Equivalent \\n' + watershedName\n",
    "plt.title(titleText);\n",
    "plt.xlabel(\"Water Year Days\");\n",
    "plt.ylabel(\"Snow Water Equivalent (mm)\");\n",
    "#plt.setp(ax.get_xticklabels(), rotation=45)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know the wettest and driest years, lets use that information to add historical context to our graph of the year of interest. In additon, we can look at the interquartile range of SWE through time. THis is the bounds for any given day for which the SWE model is within the range 50% of the time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the interquartile range (25th percintile and 75th percintile of SWE from ERA-5 for this pixel \n",
    "#for each day of year across the record. \n",
    "DOWY=np.arange(366)\n",
    "SWE_q1=np.zeros(len(DOWY))\n",
    "SWE_q3=np.zeros(len(DOWY))\n",
    "\n",
    "for i in range(0,365):\n",
    "    #get the data for the day of the year for each year in the record\n",
    "    temp=SWEdf[SWEdf.index.dayofyear==i+1]\n",
    "    \n",
    "    #figure out which day of the water year the day of the year is (not accounting for leap year) \n",
    "    #- could make this a second step in the plot\n",
    "    if i>=274:\n",
    "        k=i-274\n",
    "    else:\n",
    "        k=i+(365-274)\n",
    "  \n",
    "    #fill in the correct day of water year location in the arrays for ploting\n",
    "    SWE_q1[k]=np.percentile(temp['SWE_mm'],25,interpolation='midpoint')\n",
    "    SWE_q3[k]=np.percentile(temp['SWE_mm'],75,interpolation='midpoint')\n",
    "\n",
    "#plot the wettest year, the driest year, the interquartile range, and the year of interest on a single graph\n",
    "\n",
    "fig, ax=plt.subplots(figsize=(15,10))\n",
    "ax.fill_between(DOWY,SWE_q1,SWE_q3)\n",
    "\n",
    "#add the wet and dry year for context\n",
    "numYears=[dryYear, wetYear]\n",
    "for i in numYears:\n",
    "    sDate=str(i-1)+'-10-01'\n",
    "    eDate=str(i)+'-09-30'\n",
    "    WY=SWEdf[sDate:eDate]\n",
    "\n",
    "\n",
    "# Add x-axis and y-axis - x axis is not year this tim ebecuase we have lots of years overlaied\n",
    "    ax.plot(list(range(len(WY))),\n",
    "            WY,\n",
    "            color='red')\n",
    "\n",
    "    # Add x-axis and y-axis\n",
    "plt.plot(list(range(len(WY_04_05))),\n",
    "         WY_04_05,\n",
    "         color='black')\n",
    "    \n",
    "    \n",
    "titleText='Daily Snow Water Equivalent \\n' + watershedName\n",
    "plt.title(titleText);\n",
    "plt.xlabel(\"Water Year Days\");\n",
    "plt.ylabel(\"Snow Water Equivalent (mm)\");\n",
    "#plt.setp(ax.get_xticklabels(), rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is interesting, dicuss with fellow students how you would interpret this graph. Is the wettest year always the most swe on a given day for a pixel? Is the driest year always the driest? \n",
    "lets now calcuate basin wide storage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
